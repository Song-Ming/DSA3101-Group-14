# -*- coding: utf-8 -*-
"""kmeans.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TWLBD4wR-rOFNKl3nR_r7G65xhryuCOJ
"""

import pandas as pd
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
import random
import numpy as np
np.random.seed(100)
file_path = "bank_marketing_dataset.csv"
df = pd.read_csv(file_path)
df = df.replace('unknown', pd.NA)
for col in df.columns:
    df[col] = df[col].fillna(df[col].mode()[0])
categorical_cols = ['job', 'marital', 'education','default','housing', 'loan', 'poutcome', 'contact', 'month', 'day_of_week']
if 'subscribed' in df.columns:
    df['subscribed'] = df['subscribed'].map({'no': 0, 'yes': 1})
df_cleaned = pd.get_dummies(df, columns=categorical_cols, drop_first=True).astype(int)
df_cleaned.head()
df_unscaledcopy = df_cleaned.copy()
scaler = StandardScaler()
numerical_cols = ['age', 'duration','campaign', 'pdays', 'previous','emp.var.rate', 'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed']
df_cleaned[numerical_cols] = scaler.fit_transform(df_cleaned[numerical_cols])
df_cleaned = df_cleaned.drop(columns=['duration'])
df_cleaned.to_csv("preprocessed_bank_marketing.csv", index=False)

# Define range for potential cluster numbers
wcss = []
K_range = range(2, 11)  # Checking clusters from 2 to 10

# k-means for each k and compute wcss
for k in K_range:
    kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
    kmeans.fit(df_cleaned)
    wcss.append(kmeans.inertia_)

# Plot Elbow Method graph
plt.figure(figsize=(8, 5))
plt.plot(K_range, wcss, marker='o', linestyle='-')
plt.xlabel('Number of Clusters (K)')
plt.ylabel('WCSS (Within-Cluster Sum of Squares)')
plt.title('Elbow Method for Optimal K')
plt.show()

# Apply KMeans clustering with k=3
k = 3
kmeans = KMeans(n_clusters=k, random_state=42, n_init=10)
df_cleaned['cluster'] = kmeans.fit_predict(df_cleaned)
df_unscaledcopy['cluster']=df_cleaned['cluster'] ##for visualisation of clusters

# Perform PCA to reduce the data to 2 components for visualisation
pca = PCA(n_components=2)
reduced_data = pca.fit_transform(df_cleaned.drop(columns=['subscribed', 'cluster']))

plt.figure(figsize=(10, 8))
plt.scatter(reduced_data[:, 0], reduced_data[:, 1], c=df_cleaned['cluster'], cmap='viridis', alpha=0.6)
plt.title(f'KMeans Clustering with k={k} (PCA-reduced data)')
plt.xlabel('Principal Component 1')
plt.ylabel('Principal Component 2')
plt.colorbar(label='Cluster')
plt.show()

cluster_means = df_cleaned.groupby('cluster').mean()
print(cluster_means)

import pandas as pd

pd.set_option('display.max_columns', None)
print(cluster_means)

##cluster 2 has highest rate of success for previous campaigns, while most of cluster 1 was not contacted

import seaborn as sns
import matplotlib.pyplot as plt
plt.figure(figsize=(10, 6))
sns.histplot(data=df_unscaledcopy, x='age', hue='cluster', kde=True, bins=30, palette='Set1')
plt.title('Age Distribution Across Clusters')
plt.xlabel('Age')
plt.ylabel('Frequency')
plt.show()

##age in clusters are more or less similar, which 30-40 being the majority, cluster 0 of a slightly younger age

import pandas as pd
import matplotlib.pyplot as plt

job_columns = [col for col in df_unscaledcopy.columns if 'job_' in col]
job_distribution = df_unscaledcopy.groupby('cluster')[job_columns].sum()
job_distribution_proportions = job_distribution.div(job_distribution.sum(axis=1), axis=0)
job_distribution_proportions.plot(kind='bar', stacked=True, figsize=(12, 6),colormap='Set3') ##proportion easier to compare because clusters are of different size
plt.title('Proportion of Job Types by Cluster')
plt.xlabel('Cluster')
plt.ylabel('Proportion')
plt.xticks(rotation=0)
plt.legend(title='Job Types', bbox_to_anchor=(1.05, 1), loc='upper left')

plt.tight_layout()
plt.show()
##Cluster 2 has higher proportion of student and retired population, thus this group may opt for low-risk financial products
##Both Cluster 0 and Cluster 1 has diverse job types, but cluster 1 has higher proportion of higher-paid jobs like entrepreneur, hence may be potentially targeted for future campaigns

subscribed_proportion = df_unscaledcopy.groupby(['cluster', 'subscribed']).size().unstack()
subscribed_proportion = subscribed_proportion.div(subscribed_proportion.sum(axis=1), axis=0)
subscribed_proportion.plot(kind='bar', stacked=False, figsize=(8, 6), color=['#FF9999', '#66B3FF'])
plt.title('Subscribed Proportion by Cluster')  ##proportion for easier comparison
plt.xlabel('Cluster')
plt.ylabel('Proportion')
plt.legend(title='Subscription Status', loc='upper right')
plt.xticks(rotation=0)
plt.show()

##higher proportion of cluster 2 subscribed to term deposit, revealing their interests in more financial secure campaigns, while cluster 0 has higher proportion of engagement than cluster 1

#Cluster 0: Diverse job types. Moderate subscription to term deposits. Contacted less frequently, and response rate is low.
#Cluster 1: Diverse job types with more high paying jobs. Lowest subsciption to term deposits. Most were never contacted for previous marketing campaigns.
#Cluster 2: Relatively higher proportion of retired individuals and students, higher subscription to term deposits. Contacted recently and response to marketing campaign is high